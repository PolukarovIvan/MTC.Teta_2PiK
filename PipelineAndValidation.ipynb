{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:13:20.901531Z",
     "iopub.status.busy": "2021-08-06T00:13:20.901050Z",
     "iopub.status.idle": "2021-08-06T00:13:20.909027Z",
     "shell.execute_reply": "2021-08-06T00:13:20.908280Z",
     "shell.execute_reply.started": "2021-08-06T00:13:20.901500Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-06d09dff8b4b>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-06d09dff8b4b>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    from sklearn.metrics import from sklearn.metrics import make_scorer, roc_auc_score, f1_score\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, f1_score\n",
    "from sklearn.metrics import from sklearn.metrics import make_scorer, roc_auc_score, f1_score \n",
    "\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.153046Z",
     "iopub.status.busy": "2021-08-06T00:10:35.152715Z",
     "iopub.status.idle": "2021-08-06T00:10:35.183663Z",
     "shell.execute_reply": "2021-08-06T00:10:35.182527Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.153014Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "file_name = \"BPL.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.206390Z",
     "iopub.status.busy": "2021-08-06T00:10:35.206027Z",
     "iopub.status.idle": "2021-08-06T00:10:35.229355Z",
     "shell.execute_reply": "2021-08-06T00:10:35.228309Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.206355Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are no nulls there\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.231626Z",
     "iopub.status.busy": "2021-08-06T00:10:35.231041Z",
     "iopub.status.idle": "2021-08-06T00:10:35.240862Z",
     "shell.execute_reply": "2021-08-06T00:10:35.239707Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.231558Z"
    }
   },
   "outputs": [],
   "source": [
    "# numeric and categorical features\n",
    "num_cols = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage', 'Family', 'Education', 'ZIP Code']\n",
    "intersection_cols = ['Education', 'Family']\n",
    "cat_cols = list((set(df.columns) - set(num_cols)).union(set(intersection_cols)))\n",
    "\n",
    "print('Numeric Columns:', num_cols)\n",
    "print('Categorical Columns:', cat_cols)\n",
    "print('Intersection Columns:', intersection_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.242960Z",
     "iopub.status.busy": "2021-08-06T00:10:35.242533Z",
     "iopub.status.idle": "2021-08-06T00:10:35.309678Z",
     "shell.execute_reply": "2021-08-06T00:10:35.308647Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.242927Z"
    }
   },
   "outputs": [],
   "source": [
    "# negative Experience...\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.312143Z",
     "iopub.status.busy": "2021-08-06T00:10:35.311785Z",
     "iopub.status.idle": "2021-08-06T00:10:35.360762Z",
     "shell.execute_reply": "2021-08-06T00:10:35.359722Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.312110Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().loc['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-06T00:10:35.585662Z",
     "iopub.status.busy": "2021-08-06T00:10:35.585166Z",
     "iopub.status.idle": "2021-08-06T00:10:35.594513Z",
     "shell.execute_reply": "2021-08-06T00:10:35.593316Z",
     "shell.execute_reply.started": "2021-08-06T00:10:35.585552Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "fig, ax = plt.subplots(4, 2, figsize=(16, 20))\n",
    "\n",
    "for current_column, axis in zip(num_cols, ax.flatten()):\n",
    "    sns.boxplot(x='Personal Loan', y=current_column, data=df, ax=axis)\n",
    "    axis.axhline(df.describe().loc['75%', current_column], ls='--', c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "target_col = ['Personal Loan']\n",
    "\n",
    "X, y = df.drop(target_col, axis=1), df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(TransformerMixin, BaseEstimator):\n",
    "    '''\n",
    "    Custom Transforemr.\n",
    "    Drops columns: ID, ZIP Code,'Age, Experience.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform X via code or additional methods\n",
    "        # print(X.columns)\n",
    "        return X.drop([\"ID\", \"ZIP Code\", 'Age', 'Experience'], axis=1)\n",
    "    \n",
    "    \n",
    "class FeatureGemerator(TransformerMixin, BaseEstimator):\n",
    "    '''\n",
    "    Custom Transforemr.\n",
    "    Creates several categorical columns\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform X via code or additional methods\n",
    "        \n",
    "        # is sth features\n",
    "        X['IsMortgaged'] = X['Mortgage'] > 0\n",
    "        X['IsFamily'] = X['Family'] > 1\n",
    "        X['IsEducated'] = X['Education'] > 1\n",
    "\n",
    "        # Is > than 75 qq\n",
    "        X['IsMortgaged75'] = (X['Mortgage'] > X.describe().loc['75%', 'Mortgage']) & X['IsMortgaged']\n",
    "        X['IsIncome75'] = X['Income'] > X.describe().loc['75%', 'Income']\n",
    "        X['IsCCAvg75'] = X['CCAvg'] > X.describe().loc['75%', 'CCAvg']\n",
    "        \n",
    "        return X\n",
    "    \n",
    "def add_layer_to_pipeline(pipeline, layer,\n",
    "                             pipeline_name='pipe', layer_name='model'):\n",
    "    new_pipeline = Pipeline([\n",
    "        (pipeline_name, pipeline),\n",
    "        (layer_name, layer)\n",
    "    ])\n",
    "    \n",
    "    return new_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-13445c650946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# creating a pipeline to preprocess data in future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m data_engeneering_pipeline = Pipeline([\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'feature_generator'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFeatureGemerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'feature_selector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFeatureSelector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'scaler'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a pipeline to preprocess data in future\n",
    "data_engeneering_pipeline = Pipeline([\n",
    "    ('feature_generator', FeatureGemerator()),\n",
    "    ('feature_selector', FeatureSelector()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# savling pipeline\n",
    "joblib.dump(data_engeneering_pipeline, 'data_engeneering_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of preprocessing\n",
    "X_train = data_engeneering_pipeline.fit_transform(X_train)\n",
    "X_test = data_engeneering_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing models, their params and metrics\n",
    "models = {'RandomForestClassifier': RandomForestClassifier(),\n",
    "          'LogisticRegression': LogisticRegression(),\n",
    "          'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "          'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "          'GradientBoostingClassifier': GradientBoostingClassifier()}\n",
    "\n",
    "params = {'LogisticRegression': {'C': np.linspace(0.01,2,15),\n",
    "                                 'penalty': ['l1','l2', 'elasticnet', 'none']},\n",
    "          'RandomForestClassifier': {'max_features': [1,3,10],\n",
    "                                      'min_samples_split': [2,3,10],\n",
    "                                      'min_samples_leaf': [1,3,10],\n",
    "                                      'bootstrap': [False, True],\n",
    "                                      'n_estimators': [50, 100, 200, 300],\n",
    "                                      'n_jobs': [-1]},\n",
    "          'DecisionTreeClassifier': {'splitter': ['best', 'random'],\n",
    "                                     'max_depth': ['none'] + [i for i in range(3, 9)]},\n",
    "          'KNeighborsClassifier':  {'n_neighbors': np.arange(1,50),\n",
    "                                    'weights': ['uniform', 'distance']},\n",
    "          'GradientBoostingClassifier': {'learning_rate': [0.001,0.01,0.1,0.05],\n",
    "                                         'n_estimators': [100,500,1000],\n",
    "                                         'max_depth': [3,5,10],\n",
    "                                         'min_samples_split': [2,5,10]}\n",
    "}\n",
    "\n",
    "metrics = {'accuracy': accuracy_score,\n",
    "           'precision': precision_score,\n",
    "           'recall': recall_score,\n",
    "           'roc_auc': roc_auc_score, \n",
    "           'f1': f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_grdsearch_and_evaluate(X_train, y_train, X_test, y_test, \n",
    "                                 models=models, params=params, metrics=metrics, \n",
    "                                 n_jobs=-1, verbose=1, scoring='roc_auc', n_splits=5):\n",
    "    '''\n",
    "    Returns a matrix (pd.DataFrame) of scores, dict of best_models \\\n",
    "    and dict of their best validation_scores(roc_auc)  \n",
    "    '''\n",
    "    \n",
    "    best_scores={}\n",
    "    best_estimators={}\n",
    "    \n",
    "    df_models = []\n",
    "    df_training_scores = []\n",
    "    df_scores = {metric_name:[] for metric_name, _ in metrics.items()}\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns=['model'] + list(df_scores.values()))\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        search = GridSearchCV(model, param_grid=params[model_name], \n",
    "                              cv=StratifiedKFold(n_splits=5), scoring='roc_auc',\n",
    "                              n_jobs=n_jobs, verbose=verbose).fit(X_train, y_train)\n",
    "        \n",
    "        best_scores[model_name] = search.best_score_\n",
    "        best_estimators[model_name] = search.best_estimator_       \n",
    "        print(f'Model: {model_name},\\nBest score: \\\n",
    "        {best_scores[model_name]}\\nBest params: {best_estimators[model_name]}')            \n",
    "        \n",
    "        df_models.append(model_name)\n",
    "\n",
    "        for score_name, score in metrics.items():\n",
    "            # f1 and accuracy don't work with probas\n",
    "            # Also RFClassifier don't have predict_proba\n",
    "            try:\n",
    "                preds = search.predict_proba(X_test)\n",
    "                df_scores[score_name].append(score(y_test, preds))\n",
    "            except Exception as e:\n",
    "                preds = search.predict(X_test)\n",
    "                df_scores[score_name].append(score(y_test, preds))\n",
    "        \n",
    "    df['model'] = df_models\n",
    "        \n",
    "    for score_name, _ in df_scores.items():\n",
    "        df[score_name] = df_scores[score_name]\n",
    "            \n",
    "    return df, best_estimators, best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scoring_df, best_params, best_scores = train_grdsearch_and_evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scores to csv\n",
    "scoring_df.to_csv('scoring_df.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation results\n",
    "scoring_df = pd.read_csv('scoring_df.csv')\n",
    "scoring_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation vizualiazation\n",
    "fig = plt.figure(figsize=(16, 7))\n",
    "for i in range(len(scoring_df)):\n",
    "    plt.plot(metrics.keys(), scoring_df.loc[i, metrics.keys()].values, label=scoring_df['model'][i])\n",
    "\n",
    "plt.title('Scores of models', fontsize=18)\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model\n",
    "final_model = best_params['DecisionTreeClassifier']\n",
    "\n",
    "#saving model\n",
    "joblib.dump(final_model, 'final_model.pkl')\n",
    "\n",
    "# final score\n",
    "preds = final_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
